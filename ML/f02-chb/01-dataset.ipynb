{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "ml_venv",
   "display_name": "ML_venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHB em csv\n",
    "\n",
    "Gerando arquivos csv em cada pasta CHB\n",
    "\n",
    "> `neg` e `pos` em variáveis se referem às classes (`target`):\n",
    "    \n",
    "- 0: negativo\n",
    "- 1: positivo\n",
    "\n",
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from pywt import wavedec\n",
    "from statsmodels.robust.scale import mad as medianAD\n",
    "\n",
    "file_range = ['21', '22', '23', '24']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['std', 'mean', 'skew', 'kurt', 'meanAD', 'medianAD', 'energy']\n",
    "\n",
    "# Colunas do Dataset com DWT\n",
    "decomposition_level = 5\n",
    "\n",
    "dwt_coefs = [f'A{decomposition_level}'] + [f'D{level}' for level in range(1, decomposition_level + 1)]\n",
    "\n",
    "labels_com_dwt = [\n",
    "    f'{feat}-{coef}-{column}' for column in range(18) for coef in dwt_coefs for feat in features\n",
    "] + ['target']\n",
    "\n",
    "# Colunas do Dataset sem DWT\n",
    "labels_sem_dwt = [\n",
    "    f'{feat}-{column}' for column in range(18) for feat in features\n",
    "] + ['target']\n",
    "\n",
    "\n",
    "def energy(mat: np.ndarray) -> np.float64: return (mat ** 2).sum(axis=1)\n",
    "\n",
    "\n",
    "def extract_features_sem_dwt(matrix: np.ndarray, target: np.float64) -> pd.DataFrame:\n",
    "    '''\n",
    "    É esperado como entrada uma matrix de dimensões 18 x 512.\n",
    "\n",
    "    Durante a execução, um dataframe statsDF de dimensões 7 x 18\n",
    "\n",
    "    Ao fim um DataFrame com 127 colunas e 1 linha\n",
    "    126 (7 * 18 do statsDF) + 1 (do target)\n",
    "    '''\n",
    "\n",
    "    matrixDF, statsDF = pd.DataFrame(data=matrix).transpose(), pd.DataFrame()\n",
    "\n",
    "    energy = lambda mat: (mat ** 2).sum(axis=1)\n",
    "\n",
    "    statsDF['std'] = matrixDF.std()\n",
    "    statsDF['mean'] = matrixDF.mean()\n",
    "    statsDF['skew'] = matrixDF.skew()\n",
    "    statsDF['kurt'] = matrixDF.kurt()\n",
    "    statsDF['meanAD'] = matrixDF.mad()\n",
    "    statsDF['medianAD'] = medianAD(matrixDF)\n",
    "    statsDF['energy'] = energy(matrix)\n",
    "\n",
    "    # Redimensionando matriz para uma linha e concatenando target à lista\n",
    "    column = list(statsDF.values.reshape(126)) + [target]\n",
    "\n",
    "    return pd.DataFrame(data=column, index=labels_sem_dwt).transpose()\n",
    "\n",
    "\n",
    "def extract_features_com_dwt(matrix: np.ndarray, target: np.float64) -> pd.DataFrame:\n",
    "    '''\n",
    "    É esperado como entrada uma matrix de dimensões 18 x 512.\n",
    "\n",
    "    Durante a execução, para cada uma das 18 colunas,\n",
    "    é gerado uma lista de 6 arrays de tamanhos variados\n",
    "    em função da wavedec.\n",
    "    De cada um dos 6 arrays é extraido 7 features.\n",
    "\n",
    "    um dataframe statsDF de dimensões 1 x 757 é retornado\n",
    "    com as features calculadas.\n",
    "    '''\n",
    "    statsDF = pd.DataFrame(columns=labels_com_dwt)\n",
    "    energy = lambda mat: (mat ** 2).sum()\n",
    "\n",
    "    for i, column in enumerate(matrix):\n",
    "        wavelet_coefs = wavedec(\n",
    "            data=column,\n",
    "            wavelet='db2',\n",
    "            level=decomposition_level\n",
    "        )\n",
    "\n",
    "        for coef, coef_label in zip(wavelet_coefs, dwt_coefs):\n",
    "            coefDF = pd.DataFrame(data=coef, dtype=np.float64)\n",
    "\n",
    "            statsDF[f'std-{coef_label}-{i}'] = coefDF.std()\n",
    "            statsDF[f'mean-{coef_label}-{i}'] = coefDF.mean()\n",
    "            statsDF[f'skew-{coef_label}-{i}'] = coefDF.skew()\n",
    "            statsDF[f'kurt-{coef_label}-{i}'] = coefDF.kurt()\n",
    "            statsDF[f'meanAD-{coef_label}-{i}'] = coefDF.mad()\n",
    "            statsDF[f'medianAD-{coef_label}-{i}'] = medianAD(coefDF)\n",
    "            statsDF[f'energy-{coef_label}-{i}'] = energy(coef)\n",
    "\n",
    "    statsDF['target'] = target\n",
    "    return statsDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando arquivos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CHB21:\tPositive files: 96;\tTotal files: 10890;\nCHB22:\tPositive files: 99;\tTotal files: 50479;\nCHB23:\tPositive files: 207;\tTotal files: 7028;\nCHB24:\tPositive files: 244;\tTotal files: 7077;\n"
    }
   ],
   "source": [
    "for i in file_range:\n",
    "    # Carregando Matrizes de arquivo zip\n",
    "    with ZipFile(f'./chb{i}/chb{i}.zip') as data:\n",
    "        # Cria uma lista com os nomes dos arquivos dentro do zip e os ordena\n",
    "        file_list = data.namelist()\n",
    "        file_list.sort()\n",
    "\n",
    "        pos_list = [pos for pos in file_list if (f'chb{i}/positive/' in pos)]\n",
    "        pos_len = len(pos_list)\n",
    "        tot_len = len(file_list)\n",
    "        neg_list = [file_list[i] for i in range(pos_len)]\n",
    "\n",
    "        print(f'CHB{i}:\\tPositive files: {pos_len};\\tTotal files: {tot_len};')\n",
    "\n",
    "        pos_space, neg_space = [], []\n",
    "\n",
    "        # Cada arquivo é uma matriz que será salva nas listas {pos, neg}_space\n",
    "        for pos_file, neg_file in zip(pos_list, neg_list):\n",
    "            with data.open(name=pos_file, mode='r') as pos, data.open(name=neg_file, mode='r') as neg:\n",
    "                pos_space.append(np.load(pos))\n",
    "                neg_space.append(np.load(neg))\n",
    "\n",
    "        # Convertendo listas para arrays\n",
    "        pos_space = np.array(pos_space, dtype=np.float64)\n",
    "        neg_space = np.array(neg_space, dtype=np.float64)\n",
    "\n",
    "        # Gerando dataframe sem DWT\n",
    "        dataset_sem_dwt = pd.DataFrame(columns=labels_sem_dwt)\n",
    "\n",
    "        neg_df_list_sem_dwt = [extract_features_sem_dwt(neg_mat, 0) for neg_mat in neg_space]\n",
    "        pos_df_list_sem_dwt = [extract_features_sem_dwt(pos_mat, 1) for pos_mat in pos_space]\n",
    "\n",
    "        tot_df_list_sem_dwt = neg_df_list_sem_dwt + pos_df_list_sem_dwt\n",
    "\n",
    "        dataset_sem_dwt = pd.concat(tot_df_list_sem_dwt, ignore_index=True)\n",
    "\n",
    "        # Gerando dataframe com DWT\n",
    "        dataset_com_dwt = pd.DataFrame(columns=labels_com_dwt)\n",
    "\n",
    "        neg_df_list_com_dwt = [extract_features_com_dwt(neg_mat, 0) for neg_mat in neg_space]\n",
    "        pos_df_list_com_dwt = [extract_features_com_dwt(pos_mat, 1) for pos_mat in pos_space]\n",
    "\n",
    "        tot_df_list_com_dwt = neg_df_list_com_dwt + pos_df_list_com_dwt\n",
    "\n",
    "        dataset_com_dwt = pd.concat(tot_df_list_com_dwt, ignore_index=True)\n",
    "\n",
    "        # Salvando dataset em arquivo csv\n",
    "        dataset_sem_dwt.to_csv(path_or_buf=f'./chb{i}/chb{i}_sem_dwt.csv', index=False)\n",
    "        dataset_com_dwt.to_csv(path_or_buf=f'./chb{i}/chb{i}_com_dwt.csv', index=False)"
   ]
  }
 ]
}