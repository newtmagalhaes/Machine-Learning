{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentando difententes métodos com OTSU para calcular o LBP\n",
    "\n",
    "> a imagem é disposta como uma matriz no qual os pixels variam de 0 a 1.\n",
    "\n",
    "- menor: pixels abaixo do limiar de OTSU se tornam 0;\n",
    "- maior: pixels acima ou igual ao limiar de OTSU se tornam 1;\n",
    "- ambos (_default_): pixels abaixo do limiar de OTSU se tornam 0, os demais se tornam 1;\n",
    "\n",
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from zipfile import ZipFile\n",
    "from skimage.io import imread\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "from img_edit import preprocessing_img\n",
    "\n",
    "# Parâmetros do LBP\n",
    "METHOD = 'nri_uniform'\n",
    "RADIUS = 1\n",
    "N_POINTS = 8\n",
    "ZIP_PATH = 'patologias_toras.zip'\n",
    "TARGET_NAMES = {'normal': 0,\n",
    "                'broca':1,\n",
    "                'fissura': 2,\n",
    "                'musgo': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: 107 amostras\n",
      "broca: 90 amostras\n",
      "fissura: 109 amostras\n",
      "musgo: 111 amostras\n"
     ]
    }
   ],
   "source": [
    "path_dict = {name: [] for name in TARGET_NAMES}\n",
    "\n",
    "with ZipFile(ZIP_PATH) as zip_file:\n",
    "  for path in zip_file.namelist():\n",
    "    # a pasta de cada amostra é o segundo elemento do split\n",
    "    folder = path.split('/')[1]\n",
    "    # Separando amostras por classe\n",
    "    if '__MAC' not in path \\\n",
    "        and '.JPG' in path \\\n",
    "        and folder in TARGET_NAMES:\n",
    "      path_dict[folder].append(f'./{ZIP_PATH}/{path}')\n",
    "\n",
    "# Mostrando quantidade de amostras por classe\n",
    "qtd_amostras_p_classe = []\n",
    "for target in path_dict:\n",
    "  n_amostras = len(path_dict[target])\n",
    "  print(f'{target}: {n_amostras} amostras')\n",
    "\n",
    "  qtd_amostras_p_classe.append(n_amostras)\n",
    "\n",
    "N_MIN_DE_AMOSTRAS = min(qtd_amostras_p_classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menor(arr, limiar) -> np.ndarray:\n",
    "  img_otsu = arr.copy()\n",
    "  img_otsu[arr<limiar] = 0\n",
    "  return img_otsu\n",
    "\n",
    "def maior(arr, limiar) -> np.ndarray:\n",
    "  img_otsu = arr.copy()\n",
    "  img_otsu[arr>=limiar] = 1\n",
    "  return img_otsu\n",
    "\n",
    "def ambos(arr, limiar) -> np.ndarray:\n",
    "  return arr >= limiar\n",
    "\n",
    "func_list = [(ambos, []),\n",
    "             (menor, []),\n",
    "             (maior, [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro no crop com imagem: (./patologias_toras.zip/patologias_toras/fissura/toras325.JPG)\n",
      "Erro no crop com imagem: (./patologias_toras.zip/patologias_toras/musgo/toras75.JPG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    90\n",
       "0    90\n",
       "3    89\n",
       "2    89\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = []\n",
    "for target_name in TARGET_NAMES:\n",
    "  path_list = path_dict[target_name]\n",
    "  path_list_slice = path_list[:N_MIN_DE_AMOSTRAS]\n",
    "\n",
    "  count = 0\n",
    "  for path in path_list_slice:\n",
    "    img = imread(path)\n",
    "    img_prepro = preprocessing_img(img)\n",
    "\n",
    "    if len(img_prepro) == 0:\n",
    "      print(f'Erro no crop com imagem: ({path})')\n",
    "      continue\n",
    "      # pode acontecer do crop horizontal recortar a imagem toda\n",
    "      # acontece erro com otsu, pula então a iteração\n",
    "      # N_MIN_DE_AMOSTRAS -= 1\n",
    "\n",
    "    # Salvando imagens\n",
    "    img_name = path.split('/')[-1].lower()\n",
    "    Image.fromarray(img_prepro, mode='L').save(f'./imgs/prepro_2/{target_name}-{img_name}.jpeg')\n",
    "\n",
    "    target_list.append(TARGET_NAMES[target_name])\n",
    "\n",
    "    for func, amostras in func_list:\n",
    "      img_otsu = func(img_prepro, threshold_otsu(img_prepro))\n",
    "\n",
    "      lbp = local_binary_pattern(image=img_otsu, P=N_POINTS, R=RADIUS, method=METHOD).flatten()\n",
    "      \n",
    "      arr = pd.Series(lbp).value_counts().sort_index().values\n",
    "      arr = arr / arr.max()\n",
    "\n",
    "      amostras.append(arr)\n",
    "\n",
    "for func, amostras in func_list:\n",
    "  data = pd.DataFrame(amostras)\n",
    "  data['target'] = target_list\n",
    "  data.dropna()\n",
    "  data.to_csv(f'./csvs/prepro_2_{func.__name__}.csv', index=False)\n",
    "\n",
    "pd.Series(target_list).value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
